{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 files belonging to 2 classes.\n",
      "Using 34 files for training.\n",
      "Found 42 files belonging to 2 classes.\n",
      "Using 8 files for validation.\n"
     ]
    }
   ],
   "source": [
    "WIDTH, HEIGHT = (256, 256)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"./photo_samples/\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(WIDTH, HEIGHT),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "# test_ds = train_ds.take(1000)\n",
    "# train_ds = train_ds.skip(1000)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"./photo_samples/\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(WIDTH, HEIGHT),\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 14:30:17.754209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x2c49eef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6563 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 14:30:18.826682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x29b84f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6563 - accuracy: 0.0000e+00 - val_loss: 1.3365 - val_accuracy: 0.3750\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 1.0779 - accuracy: 0.5294 - val_loss: 0.9933 - val_accuracy: 0.6250\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 1.1715 - accuracy: 0.4706 - val_loss: 0.7770 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bb262fa0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 14:31:09.264640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x2ece289d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00\n",
      "0 input_16\n",
      "1 conv2d_861\n",
      "2 batch_normalization_846\n",
      "3 activation_846\n",
      "4 conv2d_862\n",
      "5 batch_normalization_847\n",
      "6 activation_847\n",
      "7 conv2d_863\n",
      "8 batch_normalization_848\n",
      "9 activation_848\n",
      "10 max_pooling2d_51\n",
      "11 conv2d_864\n",
      "12 batch_normalization_849\n",
      "13 activation_849\n",
      "14 conv2d_865\n",
      "15 batch_normalization_850\n",
      "16 activation_850\n",
      "17 max_pooling2d_52\n",
      "18 conv2d_869\n",
      "19 batch_normalization_854\n",
      "20 activation_854\n",
      "21 conv2d_867\n",
      "22 conv2d_870\n",
      "23 batch_normalization_852\n",
      "24 batch_normalization_855\n",
      "25 activation_852\n",
      "26 activation_855\n",
      "27 average_pooling2d_81\n",
      "28 conv2d_866\n",
      "29 conv2d_868\n",
      "30 conv2d_871\n",
      "31 conv2d_872\n",
      "32 batch_normalization_851\n",
      "33 batch_normalization_853\n",
      "34 batch_normalization_856\n",
      "35 batch_normalization_857\n",
      "36 activation_851\n",
      "37 activation_853\n",
      "38 activation_856\n",
      "39 activation_857\n",
      "40 mixed0\n",
      "41 conv2d_876\n",
      "42 batch_normalization_861\n",
      "43 activation_861\n",
      "44 conv2d_874\n",
      "45 conv2d_877\n",
      "46 batch_normalization_859\n",
      "47 batch_normalization_862\n",
      "48 activation_859\n",
      "49 activation_862\n",
      "50 average_pooling2d_82\n",
      "51 conv2d_873\n",
      "52 conv2d_875\n",
      "53 conv2d_878\n",
      "54 conv2d_879\n",
      "55 batch_normalization_858\n",
      "56 batch_normalization_860\n",
      "57 batch_normalization_863\n",
      "58 batch_normalization_864\n",
      "59 activation_858\n",
      "60 activation_860\n",
      "61 activation_863\n",
      "62 activation_864\n",
      "63 mixed1\n",
      "64 conv2d_883\n",
      "65 batch_normalization_868\n",
      "66 activation_868\n",
      "67 conv2d_881\n",
      "68 conv2d_884\n",
      "69 batch_normalization_866\n",
      "70 batch_normalization_869\n",
      "71 activation_866\n",
      "72 activation_869\n",
      "73 average_pooling2d_83\n",
      "74 conv2d_880\n",
      "75 conv2d_882\n",
      "76 conv2d_885\n",
      "77 conv2d_886\n",
      "78 batch_normalization_865\n",
      "79 batch_normalization_867\n",
      "80 batch_normalization_870\n",
      "81 batch_normalization_871\n",
      "82 activation_865\n",
      "83 activation_867\n",
      "84 activation_870\n",
      "85 activation_871\n",
      "86 mixed2\n",
      "87 conv2d_888\n",
      "88 batch_normalization_873\n",
      "89 activation_873\n",
      "90 conv2d_889\n",
      "91 batch_normalization_874\n",
      "92 activation_874\n",
      "93 conv2d_887\n",
      "94 conv2d_890\n",
      "95 batch_normalization_872\n",
      "96 batch_normalization_875\n",
      "97 activation_872\n",
      "98 activation_875\n",
      "99 max_pooling2d_53\n",
      "100 mixed3\n",
      "101 conv2d_895\n",
      "102 batch_normalization_880\n",
      "103 activation_880\n",
      "104 conv2d_896\n",
      "105 batch_normalization_881\n",
      "106 activation_881\n",
      "107 conv2d_892\n",
      "108 conv2d_897\n",
      "109 batch_normalization_877\n",
      "110 batch_normalization_882\n",
      "111 activation_877\n",
      "112 activation_882\n",
      "113 conv2d_893\n",
      "114 conv2d_898\n",
      "115 batch_normalization_878\n",
      "116 batch_normalization_883\n",
      "117 activation_878\n",
      "118 activation_883\n",
      "119 average_pooling2d_84\n",
      "120 conv2d_891\n",
      "121 conv2d_894\n",
      "122 conv2d_899\n",
      "123 conv2d_900\n",
      "124 batch_normalization_876\n",
      "125 batch_normalization_879\n",
      "126 batch_normalization_884\n",
      "127 batch_normalization_885\n",
      "128 activation_876\n",
      "129 activation_879\n",
      "130 activation_884\n",
      "131 activation_885\n",
      "132 mixed4\n",
      "133 conv2d_905\n",
      "134 batch_normalization_890\n",
      "135 activation_890\n",
      "136 conv2d_906\n",
      "137 batch_normalization_891\n",
      "138 activation_891\n",
      "139 conv2d_902\n",
      "140 conv2d_907\n",
      "141 batch_normalization_887\n",
      "142 batch_normalization_892\n",
      "143 activation_887\n",
      "144 activation_892\n",
      "145 conv2d_903\n",
      "146 conv2d_908\n",
      "147 batch_normalization_888\n",
      "148 batch_normalization_893\n",
      "149 activation_888\n",
      "150 activation_893\n",
      "151 average_pooling2d_85\n",
      "152 conv2d_901\n",
      "153 conv2d_904\n",
      "154 conv2d_909\n",
      "155 conv2d_910\n",
      "156 batch_normalization_886\n",
      "157 batch_normalization_889\n",
      "158 batch_normalization_894\n",
      "159 batch_normalization_895\n",
      "160 activation_886\n",
      "161 activation_889\n",
      "162 activation_894\n",
      "163 activation_895\n",
      "164 mixed5\n",
      "165 conv2d_915\n",
      "166 batch_normalization_900\n",
      "167 activation_900\n",
      "168 conv2d_916\n",
      "169 batch_normalization_901\n",
      "170 activation_901\n",
      "171 conv2d_912\n",
      "172 conv2d_917\n",
      "173 batch_normalization_897\n",
      "174 batch_normalization_902\n",
      "175 activation_897\n",
      "176 activation_902\n",
      "177 conv2d_913\n",
      "178 conv2d_918\n",
      "179 batch_normalization_898\n",
      "180 batch_normalization_903\n",
      "181 activation_898\n",
      "182 activation_903\n",
      "183 average_pooling2d_86\n",
      "184 conv2d_911\n",
      "185 conv2d_914\n",
      "186 conv2d_919\n",
      "187 conv2d_920\n",
      "188 batch_normalization_896\n",
      "189 batch_normalization_899\n",
      "190 batch_normalization_904\n",
      "191 batch_normalization_905\n",
      "192 activation_896\n",
      "193 activation_899\n",
      "194 activation_904\n",
      "195 activation_905\n",
      "196 mixed6\n",
      "197 conv2d_925\n",
      "198 batch_normalization_910\n",
      "199 activation_910\n",
      "200 conv2d_926\n",
      "201 batch_normalization_911\n",
      "202 activation_911\n",
      "203 conv2d_922\n",
      "204 conv2d_927\n",
      "205 batch_normalization_907\n",
      "206 batch_normalization_912\n",
      "207 activation_907\n",
      "208 activation_912\n",
      "209 conv2d_923\n",
      "210 conv2d_928\n",
      "211 batch_normalization_908\n",
      "212 batch_normalization_913\n",
      "213 activation_908\n",
      "214 activation_913\n",
      "215 average_pooling2d_87\n",
      "216 conv2d_921\n",
      "217 conv2d_924\n",
      "218 conv2d_929\n",
      "219 conv2d_930\n",
      "220 batch_normalization_906\n",
      "221 batch_normalization_909\n",
      "222 batch_normalization_914\n",
      "223 batch_normalization_915\n",
      "224 activation_906\n",
      "225 activation_909\n",
      "226 activation_914\n",
      "227 activation_915\n",
      "228 mixed7\n",
      "229 conv2d_933\n",
      "230 batch_normalization_918\n",
      "231 activation_918\n",
      "232 conv2d_934\n",
      "233 batch_normalization_919\n",
      "234 activation_919\n",
      "235 conv2d_931\n",
      "236 conv2d_935\n",
      "237 batch_normalization_916\n",
      "238 batch_normalization_920\n",
      "239 activation_916\n",
      "240 activation_920\n",
      "241 conv2d_932\n",
      "242 conv2d_936\n",
      "243 batch_normalization_917\n",
      "244 batch_normalization_921\n",
      "245 activation_917\n",
      "246 activation_921\n",
      "247 max_pooling2d_54\n",
      "248 mixed8\n",
      "249 conv2d_941\n",
      "250 batch_normalization_926\n",
      "251 activation_926\n",
      "252 conv2d_938\n",
      "253 conv2d_942\n",
      "254 batch_normalization_923\n",
      "255 batch_normalization_927\n",
      "256 activation_923\n",
      "257 activation_927\n",
      "258 conv2d_939\n",
      "259 conv2d_940\n",
      "260 conv2d_943\n",
      "261 conv2d_944\n",
      "262 average_pooling2d_88\n",
      "263 conv2d_937\n",
      "264 batch_normalization_924\n",
      "265 batch_normalization_925\n",
      "266 batch_normalization_928\n",
      "267 batch_normalization_929\n",
      "268 conv2d_945\n",
      "269 batch_normalization_922\n",
      "270 activation_924\n",
      "271 activation_925\n",
      "272 activation_928\n",
      "273 activation_929\n",
      "274 batch_normalization_930\n",
      "275 activation_922\n",
      "276 mixed9_0\n",
      "277 concatenate_18\n",
      "278 activation_930\n",
      "279 mixed9\n",
      "280 conv2d_950\n",
      "281 batch_normalization_935\n",
      "282 activation_935\n",
      "283 conv2d_947\n",
      "284 conv2d_951\n",
      "285 batch_normalization_932\n",
      "286 batch_normalization_936\n",
      "287 activation_932\n",
      "288 activation_936\n",
      "289 conv2d_948\n",
      "290 conv2d_949\n",
      "291 conv2d_952\n",
      "292 conv2d_953\n",
      "293 average_pooling2d_89\n",
      "294 conv2d_946\n",
      "295 batch_normalization_933\n",
      "296 batch_normalization_934\n",
      "297 batch_normalization_937\n",
      "298 batch_normalization_938\n",
      "299 conv2d_954\n",
      "300 batch_normalization_931\n",
      "301 activation_933\n",
      "302 activation_934\n",
      "303 activation_937\n",
      "304 activation_938\n",
      "305 batch_normalization_939\n",
      "306 activation_931\n",
      "307 mixed9_1\n",
      "308 concatenate_19\n",
      "309 activation_939\n",
      "310 mixed10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathankumarich/.virtualenvs/mlops-wwnz/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-09-08 14:31:15.083582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e8c8df70>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 2 classes\n",
    "predictions = Dense(1, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(train_ds)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(train_ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlops-wwnz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6c9941569c7a5150c65cdb0007b79beaf61b5afc8dde94b43a6d33a8c6db982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
